{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/CuleqEcAvnIcxjuioGrR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divya6859/imdb-reviews-scraper/blob/main/MovieReviewsScrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_reviews(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
        "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "        \"Referer\": \"https://www.imdb.com/\",\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "   # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "     # Parse HTML content\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "     # Find all review containers\n",
        "      review_containers = soup.find_all('div', class_='ipc-html-content-inner-div')\n",
        "\n",
        "     # Extract and format reviews\n",
        "      reviews = [review.get_text(strip=True) for review in review_containers]\n",
        "      formatted_reviews = '\\n\\n'.join(reviews)\n",
        "\n",
        "      return formatted_reviews\n",
        "    else:\n",
        "     print(\"Failed to retrieve the page.\")\n",
        "     return None"
      ],
      "metadata": {
        "id": "vCuP2XQI6jOA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.imdb.com/title/tt1180583/reviews/?ref_=tturv_ov_ql_2'\n",
        "reviews = scrape_reviews(url)\n",
        "if reviews:\n",
        "   with open('imdb_reviews.txt', 'a', encoding='utf-8') as file:\n",
        "      file.write(reviews)\n",
        "      print(\"Reviews saved successfully.\")\n",
        "else:\n",
        "    print(\"No reviews found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc8szqNiOwZz",
        "outputId": "e000dac1-1565-435e-b96b-b1637c468c21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('imdb_reviews.csv', 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Review'])\n",
        "    for r in reviews.split('\\n\\n'):\n",
        "        writer.writerow([r])\n",
        "\n",
        "print(\"Reviews saved successfully in CSV format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig246p2UNCou",
        "outputId": "941a5dec-57a8-42ff-d9e9-890f065b2345"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews saved successfully in CSV format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHQ4Y_ojNbh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}